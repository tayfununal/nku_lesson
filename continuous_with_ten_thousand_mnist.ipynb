{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "continuous_with_ten_thousand_mnist.ipynb",
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyOavpsu82LfeayADW16LEwj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tayfununal/nku_lesson/blob/main/continuous_with_ten_thousand_mnist.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oHzEVu-9_odJ"
      },
      "source": [
        "from tensorflow.keras.datasets import mnist\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras import Model, Input\n",
        "from tensorflow.keras.layers import Flatten, Dense\n",
        "from tensorflow.keras.losses import CategoricalCrossentropy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NWHMdksl_vvI"
      },
      "source": [
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "print(\"X_train : \",X_train.shape, \" - type : \",type(X_train))\n",
        "print(\"y_train : \",y_train.shape)\n",
        "print(\"X_test : \",X_test.shape)\n",
        "print(\"y_test : \",y_test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O8SKHqOtQcll"
      },
      "source": [
        "x = X_train[np.where(y_train==0)[0][:1000]]\n",
        "y = y_train[np.where(y_train==0)[0][:1000]]\n",
        "\n",
        "x_t =  X_test[np.where(y_test==0)[0][:200]]\n",
        "y_t = y_test[np.where(y_test==0)[0][:200]]\n",
        "\n",
        "\n",
        "for i in range(1,10):\n",
        "  x_ek = X_train[np.where(y_train==i)[0][:1000]]\n",
        "  x = np.concatenate((x, x_ek))\n",
        "\n",
        "  y_ek = y_train[np.where(y_train==i)[0][:1000]]\n",
        "  y = np.concatenate((y, y_ek))\n",
        "\n",
        "  x_t_ek = X_test[np.where(y_test==i)[0][:200]]\n",
        "  x_t = np.concatenate((x_t, x_t_ek))\n",
        "\n",
        "  y_t_ek = y_test[np.where(y_test==i)[0][:200]]\n",
        "  y_t = np.concatenate((y_t, y_t_ek))\n",
        "\n",
        "print(\"Shape of x :\", x.shape)\n",
        "print(\"Shape of y :\", y.shape)\n",
        "print(\"Shape of x_t :\", x_t.shape)\n",
        "print(\"Shape of y_t :\", y_t.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o2MI6rFHFRzl"
      },
      "source": [
        "x = x.reshape(x.shape[0], 28, 28, 1)\n",
        "x_t = x_t.reshape(x_t.shape[0], 28, 28, 1)\n",
        "\n",
        "x = x.astype('float32')\n",
        "x_t = x_t.astype('float32')\n",
        "\n",
        "# Normalizing the RGB codes by dividing it to the max RGB value.\n",
        "x /= 255\n",
        "x_t /= 255\n",
        "\n",
        "print(\"Shape of x :\", x.shape)\n",
        "print(\"Shape of x_t :\", x_t.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GLukPrDzG5q1"
      },
      "source": [
        "# Adding epsilon\n",
        "tf.random.set_seed(8)\n",
        "epsilon = tf.random.normal((10000,28,28,1), mean=0, stddev= 0.00001)\n",
        "epsilon_test = tf.random.normal((2000,28,28,1), mean=0, stddev= 0.00001)\n",
        "\n",
        "X_train_with_epsilon = tf.math.add(x, epsilon)\n",
        "X_test_with_epsilon = tf.math.add(x_t, epsilon_test)\n",
        "\n",
        "print('x shape:', X_train_with_epsilon.shape)\n",
        "print('Number of images in x', X_train_with_epsilon.shape[0])\n",
        "print('Number of images in x_t', X_test_with_epsilon.shape[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kMcrttsFHjv1"
      },
      "source": [
        "# Making y_train and y_test to categorical\n",
        "y = to_categorical(y)\n",
        "y_t = to_categorical(y_t)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eZayBMgAH7cv"
      },
      "source": [
        "np.random.seed(8)\n",
        "tf.random.set_seed(8)\n",
        "\n",
        "feature_input = Input(shape=(28,28))\n",
        "\n",
        "hidden = Flatten()(feature_input)\n",
        "hidden = Dense(512, activation=\"relu\", name=\"one\")(hidden)\n",
        "hidden = Dense(512, activation=\"relu\")(hidden)\n",
        "hidden = Dense(256, activation=\"relu\")(hidden)\n",
        "hidden = Dense(256, activation=\"relu\")(hidden)\n",
        "hidden = Dense(128, activation=\"relu\")(hidden)\n",
        "\n",
        "output = Dense(10, activation='softmax')(hidden)\n",
        "\n",
        "model = Model(inputs=feature_input , outputs=output)\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wpc2HqotIJPY"
      },
      "source": [
        "batch_size = 10000\n",
        "lamdas = 1.2\n",
        "import keras.backend as K\n",
        "class CustomMSE(tf.keras.losses.Loss):\n",
        "\n",
        "    def __init__(self, regularization_factor=0.1, name=\"custom_mse\"):\n",
        "        super().__init__(name=name)\n",
        "        self.regularization_factor = regularization_factor\n",
        "\n",
        "    def call(self, y_true, y_pred):\n",
        "        # custom cross_entropy = -1/batch_size * tf.reduce_sum(y_true * tf.math.log(y_pred + 10e-15))\n",
        "        cross_entropy_loss = CategoricalCrossentropy()(y_true, y_pred)\n",
        "        reg = lamdas * (1/batch_size) * tf.reduce_sum(abs(y_pred - model(X_train_with_epsilon)))\n",
        "\n",
        "        return cross_entropy_loss + reg"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oDze2VTHIpon"
      },
      "source": [
        "# Culculating Custom Loss\n",
        "model.compile(optimizer=\"Adam\", loss=CustomMSE(), metrics=[\"accuracy\"])\n",
        "history = model.fit(x, y, epochs=50, verbose=1, batch_size=10000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "43ZfxiuqLDuv"
      },
      "source": [
        "# model.evaluate(x_t,  y_t, batch_size=2000, verbose=1)  -- reg'de model(X_train_with_epsilon) 10 000 boyutlu olduğundan sıkıntı çıkarıyor çünkü burada y_pred 2000\n",
        "y_test = to_categorical(y_test)\n",
        "model.evaluate(X_test,  y_test, batch_size=10000, verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fnO39WgKLNOu"
      },
      "source": [
        "predictions = model.predict(X_test)\n",
        "print(predictions[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jYuqdSrfJ-E8"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig, ax = plt.subplots(5, 12, figsize=(30, 18))  # 4 = row , 12= column , 30 = horizontal size , 14 = vertical size\n",
        "\n",
        "for i in range(0,5):\n",
        "  for j in range(0,12):\n",
        "    random_int = np.random.randint(1,2000,1)\n",
        "    ax[i][j].imshow(X_test[random_int].reshape((28,28)), cmap=plt.cm.binary)\n",
        "    ax[i][j].set_title(\"Value : {} \\nPredicted Value : {}\".format(int(np.where(y_test[random_int])[1]),np.argmax(predictions[random_int])))\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tVjt_4k5qd0R"
      },
      "source": [
        "# Reshaping the array to 4-dims so that it can work with the Keras API\n",
        "X_train = X_train.reshape(X_train.shape[0], 28, 28, 1)\n",
        "X_test = X_test.reshape(X_test.shape[0], 28, 28, 1)\n",
        "input_shape = (28, 28, 1)\n",
        "\n",
        "# Making sure that the values are float so that we can get decimal points after division\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "# Normalizing the RGB codes by dividing it to the max RGB value.\n",
        "X_train /= 255\n",
        "X_test /= 255"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iBwZtHm9phB4"
      },
      "source": [
        "y_train = to_categorical(y_train)\n",
        "y_test = to_categorical(y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4q3OfpeOqJmP"
      },
      "source": [
        "# Culculating Custom Loss\n",
        "model.compile(optimizer=\"Adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "history = model.fit(X_train, y_train, epochs=50, verbose=1, batch_size=60000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jANwstgRrpVJ"
      },
      "source": [
        "model.evaluate(X_test,  y_test, batch_size=10000, verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PMPTB6dJrsY9"
      },
      "source": [
        "predictions = model.predict(X_test)\n",
        "print(predictions[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1VaTLu3Nrujw"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig, ax = plt.subplots(5, 12, figsize=(30, 18))  # 4 = row , 12= column , 30 = horizontal size , 14 = vertical size\n",
        "\n",
        "for i in range(0,5):\n",
        "  for j in range(0,12):\n",
        "    random_int = np.random.randint(1,2000,1)\n",
        "    ax[i][j].imshow(X_test[random_int].reshape((28,28)), cmap=plt.cm.binary)\n",
        "    ax[i][j].set_title(\"Value : {} \\nPredicted Value : {}\".format(int(np.where(y_test[random_int])[1]),np.argmax(predictions[random_int])))\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}