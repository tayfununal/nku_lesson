{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CIFAR10_Augmentation_ty_deneme.ipynb",
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyMYzgkk13ZlJOsO3QgdfzL8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tayfununal/nku_lesson/blob/main/CIFAR10_Augmentation_ty_deneme.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I62HReV_Yh6N"
      },
      "source": [
        "import tensorflow as tf\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import numpy as np\r\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\r\n",
        "from tensorflow.keras import Sequential, Model\r\n",
        "from tensorflow.keras.layers import Dense, Input, Flatten, Conv2D, MaxPool2D, Dropout, BatchNormalization\r\n",
        "from tensorflow.keras import utils\r\n",
        "import os\r\n",
        "from tensorflow.keras.datasets import cifar10"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q2Kd4M1uYl56"
      },
      "source": [
        "# Data\r\n",
        "(X_train, y_train), (X_test, y_test) = cifar10.load_data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZOvLwscwZ3Es"
      },
      "source": [
        "datagen = ImageDataGenerator(\r\n",
        "    featurewise_center=True,\r\n",
        "    featurewise_std_normalization=True,\r\n",
        "    rotation_range=20,\r\n",
        "    width_shift_range=0.2,\r\n",
        "    height_shift_range=0.2,\r\n",
        "    horizontal_flip=True)\r\n",
        "datagen.fit(X_train)\r\n",
        "i=0\r\n",
        "for batch in datagen.flow(X_train, y_train, batch_size=50000):\r\n",
        "  i+=1\r\n",
        "  if i >5:\r\n",
        "    break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t_Rd-w0da4XX"
      },
      "source": [
        "plt.imshow(a[0][0][3])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "med0noJBb0sH"
      },
      "source": [
        "plt.imshow(X_train[2])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yKW9DUOjf7Vb"
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\r\n",
        "y_train = utils.to_categorical(y_train, 10)\r\n",
        "y_test = utils.to_categorical(y_test, 10)\r\n",
        "\r\n",
        "input = Input(shape=(32,32,3))\r\n",
        "\r\n",
        "layer1 = Conv2D(64,(3,3), padding='same', activation='swish')(input)\r\n",
        "layer2 = Conv2D(64,(3,3), padding='same', activation='swish')(layer1)\r\n",
        "layer3 = MaxPool2D(pool_size=(2,2))(layer2)\r\n",
        "#layer4 = Dropout(0.1)(layer3)\r\n",
        "\r\n",
        "layer5 = Conv2D(64,(3,3), padding='same', activation='swish')(layer3)\r\n",
        "layer6 = Conv2D(64,(3,3), padding='same', activation='relu')(layer5)\r\n",
        "layer7 = MaxPool2D(pool_size=(2,2))(layer6)\r\n",
        "#layer8 = BatchNormalization()(layer7)\r\n",
        "\r\n",
        "layer9 = Conv2D(16,(3,3), padding='same', activation='swish')(layer7)\r\n",
        "layer10 = Conv2D(16,(3,3), padding='same', activation='relu')(layer9)\r\n",
        "\r\n",
        "#layer12 = Dropout(0.2)(layer10)\r\n",
        "\r\n",
        "layer13 = Conv2D(16,(3,3), padding='same', activation='swish')(layer10)\r\n",
        "layer14 = Conv2D(16,(3,3), padding='same', activation='relu')(layer13)\r\n",
        "layer15 = MaxPool2D(pool_size=(2,2))(layer14)\r\n",
        "layer16 = Dropout(0.01)(layer15)\r\n",
        "\r\n",
        "layer17 = Conv2D(16,(3,3), padding='same', activation='swish')(layer16)\r\n",
        "layer18 = MaxPool2D(pool_size=(3,3))(layer17)\r\n",
        "#layer19 = BatchNormalization()(layer18)\r\n",
        "\r\n",
        "layer20 = Flatten()(layer18)\r\n",
        "\r\n",
        "layer21 = Dense(512, activation='swish')(layer20)\r\n",
        "layer22 = Dense(512, activation='swish')(layer21)\r\n",
        "\"\"\"\r\n",
        "layer23 = Dropout(0.01)(layer22)\r\n",
        "layer24 = Dense(16, activation='relu')(layer23)\r\n",
        "layer25 = Dropout(0.01)(layer24)\r\n",
        "\"\"\"\r\n",
        "layer26 = Dense(64, activation='swish')(layer22)\r\n",
        "layer27 = Dense(10, activation='softmax')(layer26)\r\n",
        " \r\n",
        "model = Model(input, layer27)\r\n",
        "\r\n",
        "model.compile(optimizer='rmsprop',\r\n",
        "              loss='categorical_crossentropy',\r\n",
        "              metrics=['accuracy'])\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "datagen = ImageDataGenerator(\r\n",
        "    featurewise_center=True,                #Boolean. Set input mean to 0 over the dataset, feature-wise.\r\n",
        "    featurewise_std_normalization=True,     #Boolean. Divide inputs by std of the dataset, feature-wise\r\n",
        "    rotation_range=20,                      #Int. Degree range for random rotations.\r\n",
        "    width_shift_range=0.2,                  #Float, 1-D array-like or int\r\n",
        "    height_shift_range=0.2,                 #Float, 1-D array-like or int\r\n",
        "    zoom_range = 0.2,                       #Float or [lower, upper]. Range for random zoom.\r\n",
        "    shear_range = 0.2,                      #\tFloat. Shear Intensity (Shear angle in counter-clockwise direction in degrees)\r\n",
        "    horizontal_flip=True)                   #\tBoolean. Randomly flip inputs horizontally.\r\n",
        "\r\n",
        "\r\n",
        "# compute quantities required for featurewise normalization\r\n",
        "# (std, mean, and principal components if ZCA whitening is applied)\r\n",
        "datagen.fit(x_train)\r\n",
        "# fits the model on batches with real-time data augmentation:\r\n",
        "model.fit(datagen.flow(x_train, y_train, batch_size=32),\r\n",
        "          steps_per_epoch=len(x_train) / 128, epochs=20 , validation_data=(x_test,y_test))\r\n",
        "# here's a more \"manual\" example\r\n",
        "\"\"\"\r\n",
        "for e in range(epochs):\r\n",
        "    print('Epoch', e)\r\n",
        "    batches = 0\r\n",
        "    for x_batch, y_batch in datagen.flow(x_train, y_train, batch_size=32):\r\n",
        "        model.fit(x_batch, y_batch)\r\n",
        "        batches += 1\r\n",
        "        if batches >= len(x_train) / 32:\r\n",
        "            # we need to break the loop by hand because\r\n",
        "            # the generator loops indefinitely\r\n",
        "            break\r\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FdJ0Bv2amGQc"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
