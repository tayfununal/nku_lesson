{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "continuous_last_work.ipynb",
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyOdERG2kHIyNU864YDJ+T4f",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tayfununal/nku_lesson/blob/main/continuous_last_work.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rCcSMTNOJvtD"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras import Input, Model\n",
        "from tensorflow.keras.layers import Dense, Flatten\n",
        "from tensorflow.keras.losses import categorical_crossentropy, mse, CategoricalCrossentropy\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.layers import concatenate"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XGtVqRhtLOLD"
      },
      "source": [
        "# Loading original data\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "# Reshaping the array to 4-dims so that it can work with the Keras API\n",
        "X_train = X_train.reshape(X_train.shape[0], 28, 28, 1)\n",
        "X_test = X_test.reshape(X_test.shape[0], 28, 28, 1)\n",
        "input_shape = (28, 28, 1)\n",
        "\n",
        "# Making sure that the values are float so that we can get decimal points after division\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "\n",
        "# Normalizing the RGB codes by dividing it to the max RGB value.\n",
        "X_train /= 255\n",
        "X_test /= 255\n",
        "\n",
        "print('X_train shape:', X_train.shape)\n",
        "print('Number of images in X_train', X_train.shape[0])\n",
        "print('Number of images in X_test', X_test.shape[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GT6fiwDgLkt9"
      },
      "source": [
        "# Adding epsilon\n",
        "tf.random.set_seed(8)\n",
        "epsilon = tf.random.normal((60000,28,28,1), mean=0, stddev= 0.00001)\n",
        "epsilon_test = tf.random.normal((10000,28,28,1), mean=0, stddev= 0.00001)\n",
        "\n",
        "X_train_with_epsilon = tf.math.add(X_train, epsilon)\n",
        "X_test_with_epsilon = tf.math.add(X_test, epsilon_test)\n",
        "\n",
        "print('X_train shape:', X_train_with_epsilon.shape)\n",
        "print('Number of images in X_train', X_train_with_epsilon.shape[0])\n",
        "print('Number of images in X_test', X_test_with_epsilon.shape[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FNVGrMVDLzlf"
      },
      "source": [
        "# Making y_train and y_test to categorical\n",
        "y_train = to_categorical(y_train)\n",
        "y_test = to_categorical(y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "StTMju8cMYVn"
      },
      "source": [
        "np.random.seed(8)\n",
        "tf.random.set_seed(8)\n",
        "\n",
        "feature_input = Input(shape=(28,28))\n",
        "\n",
        "hidden = Flatten()(feature_input)\n",
        "hidden = Dense(512, activation=\"relu\", name=\"one\")(hidden)\n",
        "hidden = Dense(512, activation=\"relu\")(hidden)\n",
        "hidden = Dense(256, activation=\"relu\")(hidden)\n",
        "hidden = Dense(256, activation=\"relu\")(hidden)\n",
        "hidden = Dense(128, activation=\"relu\")(hidden)\n",
        "\n",
        "output = Dense(10, activation='softmax')(hidden)\n",
        "\n",
        "model = Model(inputs=feature_input , outputs=output)\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nmXcTNtyMx0q"
      },
      "source": [
        "batch_size = 60000\n",
        "lamdas = 0.7\n",
        "import keras.backend as K\n",
        "class CustomMSE(tf.keras.losses.Loss):\n",
        "\n",
        "    def __init__(self, regularization_factor=0.1, name=\"custom_mse\"):\n",
        "        super().__init__(name=name)\n",
        "        self.regularization_factor = regularization_factor\n",
        "\n",
        "    def call(self, y_true, y_pred):\n",
        "        # custom_cross_entropy_loss = -1/batch_size * tf.reduce_sum(y_true * tf.math.log(y_pred + 10e-15))\n",
        "        cross_entropy_loss = CategoricalCrossentropy()(y_true, y_pred)\n",
        "        reg = lamdas * (1/batch_size) * tf.reduce_sum(abs(y_pred - model(X_train_with_epsilon)))\n",
        "\n",
        "        return cross_entropy_loss + reg"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5IP_UAPqMIHR"
      },
      "source": [
        "# Culculating Custom Loss\n",
        "model.compile(optimizer=\"Adam\", loss=CustomMSE(), metrics=[\"accuracy\"])\n",
        "history = model.fit(X_train, y_train, epochs=100, verbose=1, batch_size=60000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "StXq0XOsbn8k"
      },
      "source": [
        ";# Culculating Custom Loss\n",
        "model.compile(optimizer=\"Adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "history = model.fit(X_train, y_train, epochs=100, verbose=1, batch_size=60000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "54NDlcYNd7Op"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}