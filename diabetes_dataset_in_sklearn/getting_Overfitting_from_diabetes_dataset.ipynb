{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "getting_Overfitting_from_diabetes_dataset.ipynb",
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyNDRsG2rAEipIOgXewvb5Vo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tayfununal/nku_lesson/blob/main/diabetes_dataset_in_sklearn/getting_Overfitting_from_diabetes_dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YlMF0IQOuRo2"
      },
      "source": [
        "#**Getting Overfitting on Diabetes Dataset**\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g30C7sCeeFeF"
      },
      "source": [
        "import tensorflow as tf\r\n",
        "from sklearn.datasets import  load_diabetes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wKnHRp3yeWQ6"
      },
      "source": [
        "# Load the data\r\n",
        "\r\n",
        "diabetes_dataset = load_diabetes()\r\n",
        "print(diabetes_dataset[\"DESCR\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t-V-tyP0egD0"
      },
      "source": [
        "# Save the input and target variables\r\n",
        "\r\n",
        "print(diabetes_dataset.keys())\r\n",
        "\r\n",
        "data = diabetes_dataset['data']\r\n",
        "targets = diabetes_dataset['target']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L5z-ZmJRfS-a"
      },
      "source": [
        "\r\n",
        "# Normalise the target data (this will make clearer training curves)\r\n",
        "targets = (targets - targets.mean(axis=0)) / targets.std()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hWcTZb-Wfqqv"
      },
      "source": [
        "# Split the data into train and test sets\r\n",
        "\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "\r\n",
        "train_data, test_data, train_targets, test_targets = train_test_split(data, targets, test_size=0.1)\r\n",
        "\r\n",
        "print(train_data.shape)\r\n",
        "print(test_data.shape)\r\n",
        "print(train_targets.shape)\r\n",
        "print(test_targets.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nMUOfjy6gn4I"
      },
      "source": [
        "# Built the model\r\n",
        "from tensorflow.keras.models import Sequential\r\n",
        "from tensorflow.keras.layers import Dense\r\n",
        "\r\n",
        "def get_model():\r\n",
        "  model = Sequential([\r\n",
        "                      Dense(128, activation='relu', input_shape =(train_data.shape[1],)),\r\n",
        "                      Dense(128, activation='relu'),\r\n",
        "                      Dense(128, activation='relu'),\r\n",
        "                      Dense(128, activation='relu'),\r\n",
        "                      Dense(128, activation='relu'),\r\n",
        "                      Dense(128, activation='relu'),\r\n",
        "                      Dense(1)\r\n",
        "  ])\r\n",
        "  return model\r\n",
        "\r\n",
        "model = get_model()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9btVFsRCiLL1"
      },
      "source": [
        "# Print the model summary\r\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aQFac5JDiSZd"
      },
      "source": [
        "# Compile the model\r\n",
        "\r\n",
        "model.compile(optimizer='adam', loss='mse', metrics=['mae'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lofNNvHFinfV"
      },
      "source": [
        "# Train the model, with some of the data reserved for validation\r\n",
        "\r\n",
        "history = model.fit(train_data, train_targets, epochs=100,\r\n",
        "                    validation_split=0.15, batch_size=64, verbose=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NspvbQehjCqK"
      },
      "source": [
        "# Evaluate the model on the test set\r\n",
        "\r\n",
        "model.evaluate(test_data, test_targets, verbose=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gPJrqGnjjM5g"
      },
      "source": [
        "# Plot the learning curves\r\n",
        "\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ibbK78wrjZix"
      },
      "source": [
        "# Plot the training and validation loss\r\n",
        "\r\n",
        "plt.plot(history.history['loss'])\r\n",
        "plt.plot(history.history['val_loss'])\r\n",
        "plt.title('Loss vs. Epochs')\r\n",
        "plt.ylabel('Loss')\r\n",
        "plt.xlabel('Epoch')\r\n",
        "plt.legend(['Training', 'Validation'], loc='upper right')\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1-DJ1i43j9l0"
      },
      "source": [
        "# Conclusion\r\n",
        "\"\"\"\r\n",
        "    As seeing, the model is result in overfitting. You should think how to prevent the overfitting.\r\n",
        "    One of the solution to the problem is to use the regularization technique.\r\n",
        "\r\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9nbkYWIluney"
      },
      "source": [
        "# **Model Regularizations on Diabetes Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gxqg-LRruJ_V"
      },
      "source": [
        "from tensorflow.keras.layers import Dropout\r\n",
        "from tensorflow.keras import regularizers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ok0UcxJavv8j"
      },
      "source": [
        "**Adding regularization with weight dacay and dropout**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vqRC_OQNu_lT"
      },
      "source": [
        "# wd is weight decay and rate is dropout rate\r\n",
        "\r\n",
        "def get_regularised_model(wd, rate):\r\n",
        "  model = Sequential([\r\n",
        "                      Dense(128, kernel_regularizer=regularizers.l2(wd), activation='relu', input_shape=(train_data.shape[1],)),\r\n",
        "                      Dropout(rate),\r\n",
        "                      Dense(128, kernel_regularizer=regularizers.l2(wd), activation='relu'),\r\n",
        "                      Dropout(rate),\r\n",
        "                      Dense(128, kernel_regularizer=regularizers.l2(wd), activation='relu'),\r\n",
        "                      Dropout(rate),\r\n",
        "                      Dense(128, kernel_regularizer=regularizers.l2(wd), activation='relu'),\r\n",
        "                      Dropout(rate),\r\n",
        "                      Dense(128, kernel_regularizer=regularizers.l2(wd), activation='relu'),\r\n",
        "                      Dropout(rate),\r\n",
        "                      Dense(128, kernel_regularizer=regularizers.l2(wd), activation='relu'),\r\n",
        "                      Dropout(rate),\r\n",
        "                      Dense(1)\r\n",
        "  ])\r\n",
        "\r\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bnvOKwzrzx0p"
      },
      "source": [
        "# Re-built the model with weight decay and dropout layers\r\n",
        "model = get_regularised_model(1e-5, 0.3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Fsy9Bha0IYN"
      },
      "source": [
        "# Compile the model\r\n",
        "model.compile(optimizer='adam', loss='mse', metrics=['mae'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xGNm7sIw7w7s"
      },
      "source": [
        "# Train the model, with some of the data reserved for validation\r\n",
        "history = model.fit(train_data, train_targets, epochs=100,\r\n",
        "                    validation_split=0.15, batch_size=64, verbose=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Nrwi9lH8XHq"
      },
      "source": [
        "# Evaluate the model on the test set\r\n",
        "model.evaluate(test_data, test_targets, verbose=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EfU9eOLk834o"
      },
      "source": [
        "**Ploting the learning curves**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MMRP-PxY8yrm"
      },
      "source": [
        "# Plot the training and validation loss\r\n",
        "\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "\r\n",
        "plt.plot(history.history['loss'])\r\n",
        "plt.plot(history.history['val_loss'])\r\n",
        "plt.title('Loss vs. Epochs')\r\n",
        "plt.ylabel('Loss')\r\n",
        "plt.xlabel('Epoch')\r\n",
        "plt.legend(['Training', 'Validation'], loc='upper right')\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mU_BCGZy9uwd"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eaCAUPo4FC87"
      },
      "source": [
        "# **Callbacks**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4-R47ZJ8FRS1"
      },
      "source": [
        "**Introduction the callbacks**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Y2CFpS-F4O7"
      },
      "source": [
        "> **Example training callbacks**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K39Aq4uJFIPq"
      },
      "source": [
        "# Write a custom callbacks\r\n",
        "from tensorflow.keras.callbacks import Callback\r\n",
        "\r\n",
        "class Training_Callbacks(Callback):\r\n",
        "\r\n",
        "  def on_train_begin(self, logs=None):\r\n",
        "    print('Starting training...')\r\n",
        "\r\n",
        "  def on_epoch_begin(self, epoch, logs=None):\r\n",
        "    print(f'Starting epoch {epoch}')\r\n",
        "\r\n",
        "  def on_train_batch_begin(self, batch, logs=None):\r\n",
        "    print(f'Training: Starting batch {batch}')\r\n",
        "\r\n",
        "  def on_train_batch_end(self, batch, logs=None):\r\n",
        "    print(f'Training: Finished batch {batch}')\r\n",
        "  \r\n",
        "  def on_epoch_end(self, epoch, logs=None):\r\n",
        "    print(f'Finished epoch {epoch}')\r\n",
        "  \r\n",
        "  def on_train_end(self, logs=None):\r\n",
        "    print(f'Finished training!')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C9uLt8KoKsiH"
      },
      "source": [
        "# Re-built the model\r\n",
        "model = get_regularised_model(1e-5, 0.3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KpxV6vf_LL3K"
      },
      "source": [
        "# Compile the model\r\n",
        "model.compile(optimizer='adam', loss='mse')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jcwWkDszLhtn"
      },
      "source": [
        "**Train the model with the callback**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oI-uQWkDLf44"
      },
      "source": [
        "# Train the model, with some of data reserved for validation\r\n",
        "model.fit(train_data, train_targets, epochs=3, batch_size=128,verbose=False,\r\n",
        "          validation_split=0.15,\r\n",
        "          callbacks=[Training_Callbacks()])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "stGvaTPnMaut"
      },
      "source": [
        "# Write a custom callbacks\r\n",
        "from tensorflow.keras.callbacks import Callback\r\n",
        "\r\n",
        "class Testining_Callbacks(Callback):\r\n",
        "\r\n",
        "  def on_test_begin(self, logs=None):\r\n",
        "    print('Starting testing...')\r\n",
        "\r\n",
        "  def on_test_batch_begin(self, batch, logs=None):\r\n",
        "    print(f'Testing: Starting batch {batch}')\r\n",
        "\r\n",
        "  def on_test_batch_end(self, batch, logs=None):\r\n",
        "    print(f'Testing: Finished batch {batch}')\r\n",
        "  \r\n",
        "  def on_test_end(self, logs=None):\r\n",
        "    print(f'Finished testing!')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vp2iE1iVNvdn"
      },
      "source": [
        "# Evaluate the model\r\n",
        "model.evaluate(test_data, test_targets, verbose=False, callbacks=[Testining_Callbacks()])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yROlY_dSOHKi"
      },
      "source": [
        "# Write a custom callbacks\r\n",
        "from tensorflow.keras.callbacks import Callback\r\n",
        "\r\n",
        "class Prediction_Callbacks(Callback):\r\n",
        "\r\n",
        "  def on_predict_begin(self, logs=None):\r\n",
        "    print('Starting prediction...')\r\n",
        "\r\n",
        "  def on_predict_batch_begin(self, batch, logs=None):\r\n",
        "    print(f'Prediction: Starting batch {batch}')\r\n",
        "\r\n",
        "  def on_predict_batch_end(self, batch, logs=None):\r\n",
        "    print(f'Prediction: Finished batch {batch}')\r\n",
        "  \r\n",
        "  def on_predict_end(self, logs=None):\r\n",
        "    print(f'Finished prediction!')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8nWc7jx6O59_"
      },
      "source": [
        "model.predict(test_data, verbose=False, callbacks=[Prediction_Callbacks()])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VpwJ64gFTTD4"
      },
      "source": [
        "**Using the logs dictionary**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cIVwxTRXPELu"
      },
      "source": [
        "# Build the model\r\n",
        "\r\n",
        "from tensorflow.keras.models import Sequential\r\n",
        "from tensorflow.keras.layers import Dense\r\n",
        "\r\n",
        "model = tf.keras.Sequential([\r\n",
        "    Dense(128, activation='relu', input_shape=(train_data.shape[1],)),\r\n",
        "    Dense(64,activation='relu'),\r\n",
        "    tf.keras.layers.BatchNormalization(),\r\n",
        "    Dense(64, activation='relu'),\r\n",
        "    Dense(64, activation='relu'),\r\n",
        "    Dense(1)        \r\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0pVdvQoOT2uc"
      },
      "source": [
        "# Compile the model\r\n",
        "    \r\n",
        "model.compile(loss='mse', optimizer=\"adam\", metrics=['mae'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Os4TkNLiT3Hu"
      },
      "source": [
        "# Create the custom callback\r\n",
        "\r\n",
        "class LossAndMetricCallback(tf.keras.callbacks.Callback):\r\n",
        "\r\n",
        "    # Print the loss after every second batch in the training set\r\n",
        "    def on_train_batch_end(self, batch, logs=None):\r\n",
        "        if batch %2 ==0:\r\n",
        "            print('\\n After batch {}, the loss is {:7.2f}.'.format(batch, logs['loss']))\r\n",
        "    \r\n",
        "    # Print the loss after each batch in the test set\r\n",
        "    def on_test_batch_end(self, batch, logs=None):\r\n",
        "        print('\\n After batch {}, the loss is {:7.2f}.'.format(batch, logs['loss']))\r\n",
        "    \r\n",
        "    # Print the loss and mean absolute error after each epoch\r\n",
        "    def on_epoch_end(self, epoch, logs=None):\r\n",
        "        print('Epoch {}: Average loss is {:7.2f}, mean absolute error is {:7.2f}.'.format(epoch, logs['loss'], logs['mae']))\r\n",
        "    \r\n",
        "    # Notify the user when prediction has finished on each batch\r\n",
        "    def on_predict_batch_end(self,batch, logs=None):\r\n",
        "        print(\"Finished prediction on batch {}!\".format(batch))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m2RXiv2JT4gM"
      },
      "source": [
        "# Train the model\r\n",
        "\r\n",
        "history = model.fit(train_data, train_targets, epochs=20,\r\n",
        "                    batch_size=100, callbacks=[LossAndMetricCallback()], verbose=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oklu5vSiT54T"
      },
      "source": [
        "# Get predictions from the model\r\n",
        "\r\n",
        "model_pred = model.predict(test_data, batch_size=10,\r\n",
        "                           callbacks=[LossAndMetricCallback()], verbose=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V7E7imylUDb8"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}