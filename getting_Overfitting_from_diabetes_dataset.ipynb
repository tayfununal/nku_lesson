{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "getting_Overfitting_from_diabetes_dataset.ipynb",
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyMkdNhcV1Ca4fTIr2B5epo4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tayfununal/nku_lesson/blob/main/getting_Overfitting_from_diabetes_dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g30C7sCeeFeF"
      },
      "source": [
        "import tensorflow as tf\r\n",
        "from sklearn.datasets import  load_diabetes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wKnHRp3yeWQ6"
      },
      "source": [
        "# Load the data\r\n",
        "\r\n",
        "diabetes_dataset = load_diabetes()\r\n",
        "print(diabetes_dataset[\"DESCR\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t-V-tyP0egD0"
      },
      "source": [
        "# Save the input and target variables\r\n",
        "\r\n",
        "print(diabetes_dataset.keys())\r\n",
        "\r\n",
        "data = diabetes_dataset['data']\r\n",
        "targets = diabetes_dataset['target']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L5z-ZmJRfS-a"
      },
      "source": [
        "# Normalise the target data (this will make clearer training curves)\r\n",
        "targets = (targets - targets.mean(axis=0)) / targets.std()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hWcTZb-Wfqqv"
      },
      "source": [
        "# Split the data into train and test sets\r\n",
        "\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "\r\n",
        "train_data, test_data, train_targets, test_targets = train_test_split(data, targets, test_size=0.1)\r\n",
        "\r\n",
        "print(train_data.shape)\r\n",
        "print(test_data.shape)\r\n",
        "print(train_targets.shape)\r\n",
        "print(test_targets.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nMUOfjy6gn4I"
      },
      "source": [
        "# Built the model\r\n",
        "from tensorflow.keras.models import Sequential\r\n",
        "from tensorflow.keras.layers import Dense\r\n",
        "\r\n",
        "def get_model():\r\n",
        "  model = Sequential([\r\n",
        "                      Dense(128, activation='relu', input_shape =(train_data.shape[1],)),\r\n",
        "                      Dense(128, activation='relu'),\r\n",
        "                      Dense(128, activation='relu'),\r\n",
        "                      Dense(128, activation='relu'),\r\n",
        "                      Dense(128, activation='relu'),\r\n",
        "                      Dense(128, activation='relu'),\r\n",
        "                      Dense(1)\r\n",
        "  ])\r\n",
        "  return model\r\n",
        "\r\n",
        "model = get_model()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9btVFsRCiLL1"
      },
      "source": [
        "# Print the model summary\r\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aQFac5JDiSZd"
      },
      "source": [
        "# Compile the model\r\n",
        "\r\n",
        "model.compile(optimizer='adam', loss='mse', metrics=['mae'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lofNNvHFinfV"
      },
      "source": [
        "# Train the model, with some of the data reserved for validation\r\n",
        "\r\n",
        "history = model.fit(train_data, train_targets, epochs=100,\r\n",
        "                    validation_split=0.15, batch_size=64, verbose=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NspvbQehjCqK"
      },
      "source": [
        "# Evaluate the model on the test set\r\n",
        "\r\n",
        "model.evaluate(test_data, test_targets, verbose=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gPJrqGnjjM5g"
      },
      "source": [
        "# Plot the learning curves\r\n",
        "\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ibbK78wrjZix"
      },
      "source": [
        "# Plot the training and validation loss\r\n",
        "\r\n",
        "plt.plot(history.history['loss'])\r\n",
        "plt.plot(history.history['val_loss'])\r\n",
        "plt.title('Loss vs. Epochs')\r\n",
        "plt.ylabel('Loss')\r\n",
        "plt.xlabel('Epoch')\r\n",
        "plt.legend(['Training', 'Validation'], loc='upper right')\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1-DJ1i43j9l0"
      },
      "source": [
        "# Conclusion\r\n",
        "\"\"\"\r\n",
        "    As seeing, the model is result in overfitting. You should think how to prevent the overfitting.\r\n",
        "    One of the solution to the problem is to use the regularization technique.\r\n",
        "\r\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}